{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"L1 Regularization PyTorch.ipynb","provenance":[],"authorship_tag":"ABX9TyOyBG3bVnW0kkSEWVun4Ewv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":47,"metadata":{"id":"5KH-XX3qneZN","executionInfo":{"status":"ok","timestamp":1657993429788,"user_tz":-420,"elapsed":400,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}}},"outputs":[],"source":["import time\n","import copy\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data.dataset import random_split\n","from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","#!pip install torchsummary\n","from torchsummary import summary"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGvY0MpOntUS","executionInfo":{"status":"ok","timestamp":1657993430188,"user_tz":-420,"elapsed":13,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"4d68a962-89d6-47e3-f733-45c2a200b805"},"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["num_epochs = 5\n","num_classes = 10\n","batch_size = 128\n","learning_rate = 0.001"],"metadata":{"id":"ZrjJVXPpnuyU","executionInfo":{"status":"ok","timestamp":1657993430190,"user_tz":-420,"elapsed":11,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0)\n","\n","def normalize(data_tensor):\n","    '''re-scale image values to [-1, 1]'''\n","    return (data_tensor / 255.) * 2. - 1.\n","\n","transform_list = [transforms.ToTensor(\n","), transforms.Lambda(lambda x: normalize(x))]\n","\n","train_dataset = torchvision.datasets.MNIST(root='data',\n","                                           train=True,\n","                                           transform=transforms.Compose(transform_list+[\n","                                               transforms.ToPILImage(),\n","                                               transforms.ToTensor(),\n","                                               ]),\n","                                           download=True)\n","\n","\n","test_dataset = torchvision.datasets.MNIST(root='data',\n","                                          train=False,\n","                                          transform=transforms.Compose(transform_list+[\n","                                              transforms.ToPILImage(),\n","                                              transforms.ToTensor(),\n","                                              \n","                                          ]))\n","\n","# Before\n","print('Train data set:', len(train_dataset))\n","print('Test data set:', len(test_dataset))\n","\n","# Random split\n","train_set_size = int(len(train_dataset) * 0.8)\n","indices = list(range(train_set_size))\n","split = int(np.floor(.2 * train_set_size))\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler =  SequentialSampler(val_indices)\n","   \n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           sampler=train_sampler,\n","                                           batch_size=batch_size,\n","                                           )\n","\n","valid_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           sampler=valid_sampler,\n","                                           batch_size=batch_size,\n","                                           )\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=1,\n","                                          shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAUDhh3Inwb5","executionInfo":{"status":"ok","timestamp":1657993430666,"user_tz":-420,"elapsed":485,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"d5fa475c-8c52-4715-c3e7-07b02dc2296f"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Train data set: 60000\n","Test data set: 10000\n"]}]},{"cell_type":"code","source":["class ConvNet(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.non_linearity1 = nn.ReLU()\n","        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.non_linearity2 = nn.ReLU()\n","        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.fc = nn.Linear(2048, num_classes)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.max_pool1(x)\n","        x = self.non_linearity1(x)\n","\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.max_pool2(x)\n","        x = self.non_linearity2(x)\n","\n","        x = x.reshape(x.size(0), -1)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"8GFt8ZRGoDAA","executionInfo":{"status":"ok","timestamp":1657993430667,"user_tz":-420,"elapsed":29,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["model = ConvNet(num_classes).to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKkFDqWBoElr","executionInfo":{"status":"ok","timestamp":1657993430667,"user_tz":-420,"elapsed":28,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"7f50c52f-f8c1-4c2b-f543-efa54aa64f05"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConvNet(\n","  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (non_linearity1): ReLU()\n","  (max_pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n","  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (non_linearity2): ReLU()\n","  (max_pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["summary(model, input_size=(1, 28, 28))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FUavqVfUAX9T","executionInfo":{"status":"ok","timestamp":1657993430668,"user_tz":-420,"elapsed":22,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"948dc83a-9cae-42c4-8a8b-5f018d502fa8"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 30, 30]             160\n","       BatchNorm2d-2           [-1, 16, 30, 30]              32\n","         MaxPool2d-3           [-1, 16, 15, 15]               0\n","              ReLU-4           [-1, 16, 15, 15]               0\n","            Conv2d-5           [-1, 32, 17, 17]           4,640\n","       BatchNorm2d-6           [-1, 32, 17, 17]              64\n","         MaxPool2d-7             [-1, 32, 8, 8]               0\n","              ReLU-8             [-1, 32, 8, 8]               0\n","            Linear-9                   [-1, 10]          20,490\n","================================================================\n","Total params: 25,386\n","Trainable params: 25,386\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.45\n","Params size (MB): 0.10\n","Estimated Total Size (MB): 0.55\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["def train_val_model(model, criterion, optimizer, dataloaders, num_epochs=25,\n","        scheduler=None, log_interval=None):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    l1_factor = 0.0001\n","\n","    # Store losses and accuracies accross epochs\n","    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n","\n","    for epoch in range(num_epochs):\n","        if log_interval is not None and epoch % log_interval == 0:\n","            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","            print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            nsamples = 0\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                nsamples += inputs.shape[0]\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # compute loss\n","                    loss = criterion(outputs, labels)\n","\n","                    # compute L1 loss component\n","                    l1_loss = nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n","                    reg_loss = 0 \n","                    for param in model.parameters():\n","                        zero_vector = torch.rand_like(param) * 0\n","                        reg_loss += l1_loss(param, zero_vector)\n","      \n","                    # add L2 loss component\n","                    loss += reg_loss * l1_factor\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if scheduler is not None and phase == 'train':\n","                scheduler.step()\n","\n","            #nsamples = dataloaders[phase].dataset.data.shape[0]\n","            epoch_loss = running_loss / nsamples\n","            epoch_acc = running_corrects.double() / nsamples\n","\n","            losses[phase].append(epoch_loss)\n","            accuracies[phase].append(epoch_acc)\n","            if log_interval is not None and epoch % log_interval == 0:\n","                print('{} Loss: {:.4f} Acc: {:.5f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","        if log_interval is not None and epoch % log_interval == 0:\n","            print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:.5f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, losses, accuracies"],"metadata":{"id":"6egag8u8oF5A","executionInfo":{"status":"ok","timestamp":1657993430669,"user_tz":-420,"elapsed":17,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.9)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.9, nesterov=True)\n","#optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n","\n","print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n","\n","dataloaders = dict(train=train_loader, val=valid_loader)\n","\n","model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders, num_epochs=10, log_interval=1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oaXNmo8pop1D","executionInfo":{"status":"ok","timestamp":1657993556608,"user_tz":-420,"elapsed":125954,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"92bbf5bd-3c0d-40cf-9836-e092ba9fa833"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of parameters = 25386\n","Epoch 0/9\n","----------\n","train Loss: 0.2622 Acc: 0.92513\n","val Loss: 13.5253 Acc: 0.22229\n","\n","Epoch 1/9\n","----------\n","train Loss: 0.0790 Acc: 0.97674\n","val Loss: 8.4707 Acc: 0.18146\n","\n","Epoch 2/9\n","----------\n","train Loss: 0.0581 Acc: 0.98227\n","val Loss: 0.0947 Acc: 0.97083\n","\n","Epoch 3/9\n","----------\n","train Loss: 0.0454 Acc: 0.98565\n","val Loss: 0.0800 Acc: 0.97667\n","\n","Epoch 4/9\n","----------\n","train Loss: 0.0377 Acc: 0.98875\n","val Loss: 0.0984 Acc: 0.97125\n","\n","Epoch 5/9\n","----------\n","train Loss: 0.0334 Acc: 0.98878\n","val Loss: 0.1004 Acc: 0.96906\n","\n","Epoch 6/9\n","----------\n","train Loss: 0.0283 Acc: 0.99089\n","val Loss: 1.1202 Acc: 0.76292\n","\n","Epoch 7/9\n","----------\n","train Loss: 0.0257 Acc: 0.99164\n","val Loss: 0.0819 Acc: 0.97677\n","\n","Epoch 8/9\n","----------\n","train Loss: 0.0193 Acc: 0.99393\n","val Loss: 0.1016 Acc: 0.97021\n","\n","Epoch 9/9\n","----------\n","train Loss: 0.0203 Acc: 0.99362\n","val Loss: 0.0655 Acc: 0.98219\n","\n","Training complete in 2m 6s\n","Best val Acc: 0.98219\n"]}]},{"cell_type":"code","source":["_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"P08kb6ScDYpF","executionInfo":{"status":"ok","timestamp":1657993556609,"user_tz":-420,"elapsed":48,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"10d39592-209b-487c-f13a-2939869fafb8"},"execution_count":56,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the 10000 test images: {:.5f} '.format(correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v7wwewlRorTd","executionInfo":{"status":"ok","timestamp":1657993567127,"user_tz":-420,"elapsed":10525,"user":{"displayName":"Nhựt Nam Lê","userId":"16973758100827691431"}},"outputId":"a28ee7a8-e231-49bb-969d-ec7458329f19"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 0.98310 \n"]}]}]}