{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VGG Very Deep Convolutional Networks.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2QVng33uo_KW"},"outputs":[],"source":["import time\n","import copy\n","\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data.dataset import random_split\n","from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbRgmqlPpDIo","executionInfo":{"status":"ok","timestamp":1656494683409,"user_tz":-420,"elapsed":593,"user":{"displayName":"Nhut Nam Le","userId":"15620110508717858161"}},"outputId":"6d5c762d-db1b-40ce-beff-8b9504b80a98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["num_epochs = 5\n","num_classes = 10\n","batch_size = 128\n","learning_rate = 0.001"],"metadata":{"id":"wGL3nj-dpEXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0)\n","\n","def normalize(data_tensor):\n","    '''re-scale image values to [-1, 1]'''\n","    return (data_tensor / 255.) * 2. - 1.\n","\n","\n","def tile_image(image):\n","    '''duplicate along channel axis'''\n","    return image.repeat(3, 1, 1)\n","\n","\n","transform_list = [transforms.ToTensor(\n","), transforms.Lambda(lambda x: normalize(x))]\n","\n","train_dataset = torchvision.datasets.MNIST(root='data',\n","                                           train=True,\n","                                           transform=transforms.Compose(transform_list+[\n","                                               transforms.ToPILImage(),\n","                                               transforms.Resize(32),\n","                                               transforms.ToTensor(),\n","                                               transforms.Lambda(lambda x: tile_image(x)), \n","                                               transforms.Normalize((0.1307,), (0.3081,)),\n","                                               ]),\n","                                           download=True)\n","\n","\n","test_dataset = torchvision.datasets.MNIST(root='data',\n","                                          train=False,\n","                                          transform=transforms.Compose(transform_list+[\n","                                              transforms.ToPILImage(),\n","                                              transforms.Resize(32),\n","                                              transforms.ToTensor(),\n","                                              transforms.Lambda(lambda x: tile_image(x)),\n","                                              transforms.Normalize((0.1307,), (0.3081,))\n","                                          ]))\n","\n","# Before\n","print('Train data set:', len(train_dataset))\n","print('Test data set:', len(test_dataset))\n","\n","# Random split\n","train_set_size = int(len(train_dataset) * 0.8)\n","indices = list(range(train_set_size))\n","split = int(np.floor(.2 * train_set_size))\n","train_indices, val_indices = indices[split:], indices[:split]\n","\n","train_sampler = SubsetRandomSampler(train_indices)\n","valid_sampler =  SequentialSampler(val_indices)\n","   \n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           sampler=train_sampler,\n","                                           batch_size=batch_size,\n","                                           )\n","\n","valid_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           sampler=valid_sampler,\n","                                           batch_size=batch_size,\n","                                           )\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=1,\n","                                          shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rpR9jUerpFaP","executionInfo":{"status":"ok","timestamp":1656494683410,"user_tz":-420,"elapsed":24,"user":{"displayName":"Nhut Nam Le","userId":"15620110508717858161"}},"outputId":"1a2251fe-56ce-4001-aaf4-2c40c0fd3708"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train data set: 60000\n","Test data set: 10000\n"]}]},{"cell_type":"code","source":["def conv_layer_b(channel_input, channel_output):\n","    layer = nn.Sequential(\n","        nn.Conv2d(channel_input, channel_output, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(channel_output),\n","        nn.ReLU()\n","    )\n","    return layer"],"metadata":{"id":"jMDbnu9mpGp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conv_layer(channel_input, channel_output):\n","    layer = nn.Sequential(\n","        nn.Conv2d(channel_input, channel_output, kernel_size=3, padding=1),\n","        nn.ReLU(inplace=True)\n","    )\n","    return layer"],"metadata":{"id":"jxvoqvrfpLQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vgg_conv_block_b(input_list, output_list):\n","    layers = [conv_layer_b(input_list[i], output_list[i]) for i in range(len(input_list))]\n","    layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","    return nn.Sequential(*layers)"],"metadata":{"id":"mzFZahl1pNSa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vgg_conv_block(input_list, output_list):\n","    layers = [conv_layer(input_list[i], output_list[i]) for i in range(len(input_list))]\n","    layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","    return nn.Sequential(*layers)"],"metadata":{"id":"F_nzRE5EpPg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vgg_full_connected_layer(size_input, size_output):\n","    layer = nn.Sequential(\n","        nn.Linear(size_input, size_output),\n","        nn.BatchNorm1d(size_output),\n","        nn.ReLU()\n","    )\n","    return layer"],"metadata":{"id":"UucTxVInpRSm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG11(nn.Module):\n","    def __init__(self, n_classes=1000):\n","        super(VGG11, self).__init__()\n","        # Conv blocks (BatchNorm + ReLU activation added in each block)\n","\n","        ### Block 01\n","        ### Contain 1 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 64 filters, kernel size 3x3, activation function ReLU\n","        self.layer1 = vgg_conv_block(input_list=[3], output_list=[64])\n","\n","        ### Block 02\n","        ### Contain 1 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 128 filters, kernel size 3x3, activation function ReLU\n","        self.layer2 = vgg_conv_block(input_list=[64], output_list=[128])\n","\n","        ### Block 03\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 256 filters, kernel size 1x1, activation function ReLU\n","        self.layer3 = vgg_conv_block(input_list=[128, 256], output_list=[256, 256])\n","\n","        ### Block 04\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer4 = vgg_conv_block(input_list=[256, 512], output_list=[512, 512])\n","\n","\n","        ### Block 05\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer5 = vgg_conv_block(input_list=[512, 512], output_list=[512, 512])\n","\n","\n","        ## Full-Connected Layer\n","        self.layer6 = vgg_full_connected_layer(size_input=512, size_output=512)\n","        self.layer7 = vgg_full_connected_layer(size_input=512, size_output=512)\n","\n","        ## Final layer\n","        self.layer8 = nn.Linear(512, n_classes)\n","    \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        vgg11_features = self.layer5(x)\n","        x = vgg11_features.view(x.size(0), -1)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        return x"],"metadata":{"id":"eCvcrXX9pT4I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG13(nn.Module):\n","    def __init__(self, n_classes=1000):\n","        super(VGG13, self).__init__()\n","        # Conv blocks (BatchNorm + ReLU activation added in each block)\n","\n","        ### Block 01\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 64 filters, kernel size 3x3, activation function ReLU\n","        self.layer1 = vgg_conv_block(input_list=[3, 64], output_list=[64, 64])\n","\n","        ### Block 02\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 128 filters, kernel size 3x3, activation function ReLU\n","        self.layer2 = vgg_conv_block(input_list=[64, 128], output_list=[128, 128])\n","\n","        ### Block 03\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 256 filters, kernel size 1x1, activation function ReLU\n","        self.layer3 = vgg_conv_block(input_list=[128, 256], output_list=[256, 256])\n","\n","        ### Block 04\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer4 = vgg_conv_block(input_list=[256, 512], output_list=[512, 512])\n","\n","\n","        ### Block 05\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer5 = vgg_conv_block(input_list=[512, 512], output_list=[512, 512])\n","\n","\n","        ## Full-Connected Layer\n","        self.layer6 = vgg_full_connected_layer(size_input=512, size_output=512)\n","        self.layer7 = vgg_full_connected_layer(size_input=512, size_output=512)\n","\n","        ## Final layer\n","        self.layer8 = nn.Linear(512, n_classes)\n","    \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        vgg13_features = self.layer5(x)\n","        x = vgg13_features.view(x.size(0), -1)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        return x"],"metadata":{"id":"r_0o9DvbpWfm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG16_1(nn.Module):\n","    def __init__(self, n_classes=1000):\n","        super(VGG16_1, self).__init__()\n","        # Conv blocks (BatchNorm + ReLU activation added in each block)\n","\n","        ### Block 01\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 64 filters, kernel size 3x3, activation function ReLU\n","        self.layer1 = vgg_conv_block(input_list=[3, 64], output_list=[64, 64])\n","\n","        ### Block 02\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 128 filters, kernel size 3x3, activation function ReLU\n","        self.layer2 = vgg_conv_block(input_list=[64, 128], output_list=[128, 128])\n","\n","        ### Block 03\n","        ### Contain 3 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 256 filters, kernel size 1x1, activation function ReLU\n","        self.layer3 = vgg_conv_block(input_list=[128, 256, 256], output_list=[256, 256, 256])\n","\n","        ### Block 04\n","        ### Contain 3 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer4 = vgg_conv_block(input_list=[256, 512, 512], output_list=[512, 512, 512])\n","\n","\n","        ### Block 05\n","        ### Contain 3 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer5 = vgg_conv_block(input_list=[512, 512, 512], output_list=[512, 512, 512])\n","\n","\n","        ## Full-Connected Layer\n","        self.layer6 = vgg_full_connected_layer(size_input=512, size_output=512)\n","        self.layer7 = vgg_full_connected_layer(size_input=512, size_output=512)\n","\n","        ## Final layer\n","        self.layer8 = nn.Linear(512, n_classes)\n","    \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        vgg16_1_features = self.layer5(x)\n","        x = vgg16_1_features.view(x.size(0), -1)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        return x"],"metadata":{"id":"bDjOd36HpYux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG16(nn.Module):\n","    def __init__(self, n_classes=1000):\n","        super(VGG16, self).__init__()\n","        # Conv blocks (BatchNorm + ReLU activation added in each block)\n","\n","        # Block 01\n","        # Contain 2 convolution layers and 1 maxpool layer\n","        # Convolution layer has 64 filters, kernel size 3x3, activation function ReLU\n","        self.layer1 = vgg_conv_block(input_list=[3, 64], output_list=[64, 64])\n","\n","        # Block 02\n","        # Contain 2 convolution layers and 1 maxpool layer\n","        # Convolution layer has 128 filters, kernel size 3x3, activation function ReLU\n","        self.layer2 = vgg_conv_block(input_list=[64, 128], output_list=[128, 128])\n","\n","        # Block 03\n","        # Contain 3 convolution layers and 1 maxpool layer\n","        # Convolution layer has 256 filters, kernel size 3x3, activation function ReLU\n","        self.layer3 = vgg_conv_block(input_list=[128, 256, 256], output_list=[256, 256, 256])\n","\n","        # Block 04\n","        # Contain 3 convolution layers and 1 maxpool layer\n","        # Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer4 = vgg_conv_block(input_list=[256, 512, 512], output_list=[512, 512, 512])\n","\n","        # Block 05\n","        # Contain 3 convolution layers and 1 maxpool layer\n","        # Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer5 = vgg_conv_block(input_list=[512, 512, 512], output_list=[512, 512, 512])\n","\n","        ## Full-Connected Layer\n","        self.layer6 = vgg_full_connected_layer(size_input=512, size_output=512)\n","        self.layer7 = vgg_full_connected_layer(size_input=512, size_output=512)\n","\n","        ## Final layer\n","        self.layer8 = nn.Linear(512, n_classes)\n","\n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        vgg16_features = self.layer5(x)\n","        x = vgg16_features.view(x.size(0), -1)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        return x"],"metadata":{"id":"opOWahF6pbNO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VGG19(nn.Module):\n","    \n","    def __init__(self, n_classes=1000):\n","        super(VGG19, self).__init__()\n","        # Conv blocks (BatchNorm + ReLU activation added in each block)\n","\n","        ### Block 01\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 64 filters, kernel size 3x3, activation function ReLU\n","        self.layer1 = vgg_conv_block(input_list=[3, 64], output_list=[64, 64])\n","\n","        ### Block 02\n","        ### Contain 2 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 128 filters, kernel size 3x3, activation function ReLU\n","        self.layer2 = vgg_conv_block(input_list=[64, 128], output_list=[128, 128])\n","\n","        ### Block 03\n","        ### Contain 4 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 256 filters, kernel size 3x3, activation function ReLU\n","        self.layer3 = vgg_conv_block(input_list=[128, 256, 256, 256], output_list=[256, 256, 256, 256])\n","\n","        ### Block 04\n","        ### Contain 4 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer4 = vgg_conv_block(input_list=[256, 512, 512, 512], output_list=[512, 512, 512, 512])\n","\n","\n","        ### Block 05\n","        ### Contain 4 convolution layers and 1 maxpool layer\n","        ### Convolution layer has 512 filters, kernel size 3x3, activation function ReLU\n","        self.layer5 = vgg_conv_block(input_list=[512, 512, 512], output_list=[512, 512, 512])\n","\n","\n","        ## Full-Connected Layer\n","        self.layer6 = vgg_full_connected_layer(size_input=512, size_output=512)\n","        self.layer7 = vgg_full_connected_layer(size_input=512, size_output=512)\n","\n","        ## Final layer\n","        self.layer8 = nn.Linear(512, n_classes)\n","        \n","    def forward(self, x):\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        vgg19_features = self.layer5(x)\n","        x = vgg19_features.view(x.size(0), -1)\n","        x = self.layer6(x)\n","        x = self.layer7(x)\n","        x = self.layer8(x)\n","        return x"],"metadata":{"id":"J_8Vz8EppfKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = VGG11(num_classes).to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXeHc5v5plkg","executionInfo":{"status":"ok","timestamp":1656494688056,"user_tz":-420,"elapsed":4244,"user":{"displayName":"Nhut Nam Le","userId":"15620110508717858161"}},"outputId":"e96c8624-9d49-4dd2-ae61-cccb71f52294"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG11(\n","  (layer1): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer2): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer3): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer4): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer5): Sequential(\n","    (0): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (1): ReLU(inplace=True)\n","    )\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (layer6): Sequential(\n","    (0): Linear(in_features=512, out_features=512, bias=True)\n","    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (layer7): Sequential(\n","    (0): Linear(in_features=512, out_features=512, bias=True)\n","    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","  )\n","  (layer8): Linear(in_features=512, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["def train_val_model(model, criterion, optimizer, dataloaders, num_epochs=25,\n","        scheduler=None, log_interval=None):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    # Store losses and accuracies accross epochs\n","    losses, accuracies = dict(train=[], val=[]), dict(train=[], val=[])\n","\n","    for epoch in range(num_epochs):\n","        if log_interval is not None and epoch % log_interval == 0:\n","            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","            print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            nsamples = 0\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","                nsamples += inputs.shape[0]\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if scheduler is not None and phase == 'train':\n","                scheduler.step()\n","\n","            #nsamples = dataloaders[phase].dataset.data.shape[0]\n","            epoch_loss = running_loss / nsamples\n","            epoch_acc = running_corrects.double() / nsamples\n","\n","            losses[phase].append(epoch_loss)\n","            accuracies[phase].append(epoch_acc)\n","            if log_interval is not None and epoch % log_interval == 0:\n","                print('{} Loss: {:.4f} Acc: {:.5f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","        if log_interval is not None and epoch % log_interval == 0:\n","            print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:.5f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    return model, losses, accuracies"],"metadata":{"id":"SsiNxBR3prwx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.9)\n","#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.9, nesterov=True)\n","#optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n","\n","dataloaders = dict(train=train_loader, val=valid_loader)\n","\n","print(\"Total number of parameters =\", np.sum([np.prod(parameter.shape) for parameter in model.parameters()]))\n","\n","model, losses, accuracies = train_val_model(model, criterion, optimizer, dataloaders, num_epochs=10, log_interval=1)\n","\n","_ = plt.plot(losses['train'], '-b', losses['val'], '--r')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TIGZTA2psT1","executionInfo":{"status":"ok","timestamp":1656494956649,"user_tz":-420,"elapsed":268617,"user":{"displayName":"Nhut Nam Le","userId":"15620110508717858161"}},"outputId":"489c05a0-c08c-4d7e-80c1-5214d26a177d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of parameters = 9752970\n","Epoch 0/9\n","----------\n","train Loss: 0.6657 Acc: 0.76922\n","val Loss: 279.5213 Acc: 0.11333\n","\n","Epoch 1/9\n","----------\n","train Loss: 0.2554 Acc: 0.91979\n","val Loss: 1519.1722 Acc: 0.09854\n","\n","Epoch 2/9\n","----------\n","train Loss: 0.2453 Acc: 0.92315\n","val Loss: 1634.8133 Acc: 0.09927\n","\n","Epoch 3/9\n","----------\n","train Loss: 0.2649 Acc: 0.91594\n","val Loss: 272.4435 Acc: 0.11333\n","\n","Epoch 4/9\n","----------\n","train Loss: 0.1863 Acc: 0.94164\n","val Loss: 732.7827 Acc: 0.10167\n","\n","Epoch 5/9\n","----------\n","train Loss: 0.1452 Acc: 0.95302\n","val Loss: 221.2027 Acc: 0.10167\n","\n","Epoch 6/9\n","----------\n","train Loss: 0.1137 Acc: 0.96451\n","val Loss: 298.8325 Acc: 0.09854\n","\n","Epoch 7/9\n","----------\n","train Loss: 0.1359 Acc: 0.95776\n","val Loss: 2970.0072 Acc: 0.09927\n","\n","Epoch 8/9\n","----------\n","train Loss: 0.2493 Acc: 0.92286\n","val Loss: 4283.4211 Acc: 0.09927\n","\n","Epoch 9/9\n","----------\n","train Loss: 0.1842 Acc: 0.94138\n","val Loss: 896.8746 Acc: 0.08688\n","\n","Training complete in 4m 28s\n","Best val Acc: 0.11333\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","    print('Accuracy of the network on the 10000 test images: {:.5f} '.format(correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I8ZenxvLpuzs","executionInfo":{"status":"ok","timestamp":1656494980680,"user_tz":-420,"elapsed":24038,"user":{"displayName":"Nhut Nam Le","userId":"15620110508717858161"}},"outputId":"298dbc6d-dc5c-409f-909d-2752030d55d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of the network on the 10000 test images: 0.11350 \n"]}]}]}